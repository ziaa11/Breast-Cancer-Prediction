{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRzQnitYbOlMayoOZdZ7yh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Xzc0vA614Vmo","executionInfo":{"status":"ok","timestamp":1665025487800,"user_tz":-330,"elapsed":10,"user":{"displayName":"Zia Rehman","userId":"12874239748870058775"}}},"outputs":[],"source":["#Description: This program detects breast cancer, based off of data."]},{"cell_type":"code","source":["#import libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt"],"metadata":{"id":"QPA6lkA649uz","executionInfo":{"status":"ok","timestamp":1665025516415,"user_tz":-330,"elapsed":11,"user":{"displayName":"Zia Rehman","userId":"12874239748870058775"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Loading the dataset\n","from google.colab import files\n","uploaded = files.upload()\n","df = pd.read_csv('breast.csv')\n","df.head(7)"],"metadata":{"id":"GuQGtWiU5SR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#count no of rows and columns in the dataset\n","df.shape"],"metadata":{"id":"cLk-N-6E7GR3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#count the number of empty(NAN, NaN, na) values in each column\n","df.isna().sum()"],"metadata":{"id":"Hc2cYX767S8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Drop the column Unnamed(missing values)\n","df = df.dropna(axis=1)"],"metadata":{"id":"KRqAIhde7sb3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get the new count of number of rows and cols\n","df.shape"],"metadata":{"id":"bZOHJT7Z8BI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Count of the number of Malignant(M) or Benign (B) cells\n","df['diagnosis'].value_counts()"],"metadata":{"id":"y-Rj_baC8IUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Visualize count\n","sns.countplot(df['diagnosis'], label=\"Count\")"],"metadata":{"id":"mEfr0vpD9pTt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get data types of every column\n","df.dtypes"],"metadata":{"id":"LRbuuBex918B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Encoding the categorical data values\n","import seaborn as sns\n","from sklearn.preprocessing import LabelEncoder\n","labelencoder_Y = LabelEncoder()\n","df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values) #cuz diagnosis index is 1"],"metadata":{"id":"yJXveYlV-Ru8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a pair plot\n","sns.pairplot(df.iloc[:,:], hue='diagnosis')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"soTwg1YJ_vUi","executionInfo":{"status":"ok","timestamp":1664603618436,"user_tz":-330,"elapsed":931950,"user":{"displayName":"Zia Rehman","userId":"12874239748870058775"}},"outputId":"b09fe0e0-6c03-4d98-e27f-2391630b0833"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print the first 5 rows after cleaning data\n","df.head(5)"],"metadata":{"id":"l9_PAtD2DhTZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dtermining the co-relation \n","df.iloc[:,1:12].corr()"],"metadata":{"id":"Pkw-pdH_QOY3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visulaizing the co relation\n","plt.figure(figsize=(10,10))\n","sns.heatmap(df.iloc[:,1:12].corr(), annot = True)"],"metadata":{"id":"ghbZNV7DQlK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#splitting the data set into independent (x) and dependent (y) datasets\n","X = df.iloc[:,2:31].values\n","Y = df.iloc[:,1].values"],"metadata":{"id":"RK6Wj4zyREaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Splitting the dataset into training (75%) and testing (25%)\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"],"metadata":{"id":"bPMWp3eORs7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Scaling the data to bring to the same level of magnitude (Feature Scaling)\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.fit_transform(X_test)\n"],"metadata":{"id":"1xIj1m8VS9sX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a function for the models\n","def models(X_train, Y_train):\n","\n","  #Logistic regressiom Model\n","  from sklearn.linear_model import LogisticRegression\n","  log = LogisticRegression(random_state = 0)\n","  log.fit(X_train, Y_train)\n","\n","  #Decision Tree Model\n","  from sklearn.tree import DecisionTreeClassifier\n","  tree = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","  tree.fit(X_train,Y_train)\n","\n","  #Random Forest Classifier\n","  from sklearn.ensemble import RandomForestClassifier\n","  forest = RandomForestClassifier(n_estimators = 10, criterion='entropy', random_state=0)\n","  forest.fit(X_train, Y_train)\n","\n","  #Models accuracy\n","  print('[0]Logistic Regression Training Accuracy:', log.score(X_train, Y_train))\n","  print('[1]Decision Tree Classifier Training Accuracy:', tree.score(X_train, Y_train))\n","  print('[2]Random forest Training Accuracy:', forest.score(X_train, Y_train))\n","\n","  return log, tree, forest"],"metadata":{"id":"BrdKiXQ8USnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#getting all of the models\n","model = models(X_train, Y_train)"],"metadata":{"id":"jF_LUJatbZdO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" #Testing the models on test data using confusion matrix\n"," from sklearn.metrics import confusion_matrix\n"," for i in range(len(model)):\n","  print(\"Model \", i)\n","  cm = confusion_matrix(Y_test, model[i].predict(X_test))\n","\n","  TP = cm[0][0]\n","  TN = cm[1][1]\n","  FN = cm[1][0]\n","  FP = cm[0][1]\n","\n","  print(cm)\n","  print(\"Testing accuracy = \", (TP+TN)/(TP+TN+FP+FN))\n","  print()"],"metadata":{"id":"wSvDzVG9bkxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculating metrics of models\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","\n","for i in range(len(model)):\n","  print(\"Model \", i)\n","  print(classification_report(Y_test, model[i].predict(X_test)))\n","  print(accuracy_score(Y_test, model[i].predict(X_test)))\n","  print()"],"metadata":{"id":"ZSnpplODdBsu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prediction using Random Forest Classifier cuz high accuracy\n","pred = model[2].predict(X_test)\n","print(\"1 - Has Cancer\\n0 - Doesnt have cancer\\n\")\n","print(\"Predicted values\")\n","print(pred)\n","print()\n","print(\"Actual values\")\n","print(Y_test)"],"metadata":{"id":"VQIahWFYd3wG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prediction using Decison Tree Classifier cuz high accuracy\n","pred = model[1].predict(X_test)\n","print(\"1 - Has Cancer\\n0 - Doesnt have cancer\\n\")\n","print(\"Predicted values\")\n","print(pred)\n","print()\n","print(\"Actual values\")\n","print(Y_test)"],"metadata":{"id":"6WPXrSzwev0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Prediction using Logistic regression Classifier cuz high accuracy\n","pred = model[0].predict(X_test)\n","print(\"1 - Has Cancer\\n0 - Doesnt have cancer\\n\")\n","print(\"Predicted values\")\n","print(pred)\n","print()\n","print(\"Actual values\")\n","print(Y_test)"],"metadata":{"id":"uYtP9bareyNV"},"execution_count":null,"outputs":[]}]}